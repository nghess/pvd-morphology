{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Tiff Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pvd_par import PVD\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get files and paths\n",
    "def scan_directories(data_directory, min_size_bytes):\n",
    "    dataset_list = []\n",
    "    session_list = []\n",
    "    file_list = []\n",
    "\n",
    "    for root, dirs, files in os.walk(data_directory):\n",
    "        # Check if the current path contains \"exclude\" or \"movement\"\n",
    "        if \"exclude\" in root.lower() or \"movement\" in root.lower() or \"missing\" in root.lower():\n",
    "            continue  # Skip this directory\n",
    "\n",
    "        for file in files:\n",
    "            if file.endswith('.tif'):\n",
    "                file_path = os.path.join(root, file)\n",
    "\n",
    "                # Check file size\n",
    "                if os.path.getsize(file_path) < min_size_bytes:\n",
    "                    continue  # Skip this file if it's too small\n",
    "\n",
    "                path_parts = os.path.normpath(root).split(os.sep)\n",
    "                if len(path_parts) >= 3:\n",
    "                    dataset = path_parts[-2]\n",
    "                    session = path_parts[-1]\n",
    "                    dataset_list.append(dataset)\n",
    "                    session_list.append(session)\n",
    "                    file_list.append(file)\n",
    "\n",
    "    return dataset_list, session_list, file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Located 53 tiff stacks\n"
     ]
    }
   ],
   "source": [
    "# Get all tiff stacks and their paths\n",
    "data_dir = 'S:/pvd_data/'\n",
    "min_file_size = 1e8  # 100 MB\n",
    "datasets, sessions, files = scan_directories(data_dir, min_file_size)\n",
    "print(f\"Located {len(files)} tiff stacks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing tiff stack 0/53\n",
      "DataSet00 exp240104_00_01_\n",
      "Starting pipeline.\n",
      "Data loaded. Shape: (4, 92, 2044, 2042). Time: 1.81 seconds\n",
      "Data cropped. New shape: (4, 92, 2000, 2000). Time: 3.21 seconds\n",
      "Data preprocessed. Processed data shape: [(92, 2000, 2000), (92, 2000, 2000), (92, 2000, 2000), (92, 2000, 2000)]. Time: 86.73 seconds\n",
      "Skeletonizing timepoint 0\n",
      "Skeletonizing timepoint 1\n",
      "Skeletonizing timepoint 2\n",
      "Skeletonizing timepoint 3\n",
      "Completed skeletonizing timepoint 3\n",
      "Completed skeletonizing timepoint 0\n",
      "Completed skeletonizing timepoint 1\n",
      "Completed skeletonizing timepoint 2\n",
      "Data skeletonized. Time: 164.79 seconds\n",
      "Number of tips per timepoint: [214, 186, 136, 98]\n",
      "Number of knots per timepoint: [475, 452, 311, 246]\n",
      "Outer segments found. Number of outer segments per timepoint: [130, 109, 78, 52]. Time: 3.95 seconds\n",
      "Matched 7 segments across all timepoints.\n",
      "Segments matched. Number of matched segments per timepoint: [7, 7, 7, 7]. Time: 0.40 seconds\n",
      "Grouped unmatched segments across each timepoint.\n",
      "Unmatched voxels identified. Unmatched segment shapes: [(92, 2000, 2000), (92, 2000, 2000), (92, 2000, 2000), (92, 2000, 2000)]. Time: 4.10 seconds\n",
      "Starting label_segmented_volume method\n",
      "Labeling 4 timepoints\n",
      "Labelling timepoint 0\n",
      "Labelling timepoint 1\n",
      "Labelling timepoint 2\n",
      "Labelling timepoint 3\n",
      "Finished labelling timepoint 1\n",
      "Timepoint 1 volume labeled successfully.\n",
      "Finished labelling timepoint 0\n",
      "Timepoint 0 volume labeled successfully.\n",
      "Finished labelling timepoint 2\n",
      "Timepoint 2 volume labeled successfully.\n",
      "Finished labelling timepoint 3\n",
      "Timepoint 3 volume labeled successfully.\n",
      "All timepoints labeled successfully\n",
      "Finished label_segmented_volume method\n",
      "Volumes labeled. Number of labeled timepoints: 4. Time: 22.17 seconds\n",
      "Pipeline complete. Total time: 287.16 seconds\n"
     ]
    }
   ],
   "source": [
    "# Execute pipeline\n",
    "for ii, file in enumerate(files[:1]):\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # Set path\n",
    "    data_path = 'S:/pvd_data'\n",
    "    results_path = 'S:/pvd_analysis'\n",
    "    dataset = datasets[ii]\n",
    "    session = sessions[ii]\n",
    "    #tiff_stack_path = f\"{data_path}/{dataset}/{session}/{file}\"\n",
    "    output_path = f\"{results_path}/{dataset}/{session}/\"\n",
    "\n",
    "    # Process stack\n",
    "    print(f\"Processing tiff stack {ii}/{len(files)}\")\n",
    "    print(f\"{datasets[ii]} {sessions[ii]}\")\n",
    "    pvd = PVD(data_path, dataset, session, file)\n",
    "    pvd.run_pipeline()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to drive...\n",
      "Skeleton visualizations saved to S:/pvd_analysis/DataSet00/exp240104_00_01_//visualizations\n",
      "Outer segment visualizations saved to S:/pvd_analysis/DataSet00/exp240104_00_01_//visualizations\n",
      "Labeled data saved as TIFF files in S:/pvd_analysis/DataSet00/exp240104_00_01_//visualizations\n"
     ]
    }
   ],
   "source": [
    "# Save relevant numpy arrays\n",
    "print(f\"Saving data to drive...\")\n",
    "pvd.save_results(output_path, save_tiff=False, save_numpy=False, save_plotly=True, save_labeled_tiff=True)\n",
    "\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code to extract core segment indices and add to matched segments lists\n",
    "# core_segments = []\n",
    "\n",
    "# for ii in range(len(self.unmatched_segments):\n",
    "#     core_segments.append(np.where(pvd.unmatched_segments[ii] == 1))\n",
    "\n",
    "# for ii in range(len(self.unmatched_segments)):\n",
    "#     x = list(core_segments[ii][1])\n",
    "#     y = list(core_segments[ii][2])\n",
    "#     z = list(core_segments[ii][0])\n",
    "\n",
    "#     self.matched_segments[ii].append = list(zip(z,x,y))\n",
    "\n",
    "# print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set path to original test file\n",
    "# data_path = 'S:/pvd_data/'\n",
    "# results_path = 'S:/pvd_analysis'\n",
    "# dataset = 'DataSet01'\n",
    "# session = 'exp240202_01_E_'\n",
    "# file = 'exp240202_01_E.tif'\n",
    "# tiff_stack_path = f\"{data_path}/{dataset}/{session}_/{file}\"\n",
    "# output_path = f\"{results_path}/{dataset}/{session}/\"\n",
    "\n",
    "# # Process stack\n",
    "# print(f\"Processing tiff stack {ii}/{len(files)}\")\n",
    "# print(f\"{datasets[ii]} {sessions[ii]}\")\n",
    "# pvd = PVD(data_path, dataset, session, file)\n",
    "# pvd.run_pipeline()\n",
    "\n",
    "# # Save relevant numpy arrays\n",
    "# print(f\"Saving data to drive...\")\n",
    "# pvd.save_results(output_path, save_tiff=False, save_numpy=False, save_plotly=True)\n",
    "\n",
    "# time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92, 2000, 2000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvd.skeletonized_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvd.skeleton_idx = np.where(pvd.skeletonized_data[0] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
