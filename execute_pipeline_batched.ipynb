{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Tiff Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pvd_par import PVD\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get files and paths\n",
    "def scan_directories(data_directory, min_size_bytes):\n",
    "    dataset_list = []\n",
    "    session_list = []\n",
    "    file_list = []\n",
    "\n",
    "    for root, dirs, files in os.walk(data_directory):\n",
    "        # Check if the current path contains \"exclude\" or \"movement\"\n",
    "        if \"exclude\" in root.lower() or \"movement\" in root.lower() or \"missing\" in root.lower():\n",
    "            continue  # Skip this directory\n",
    "\n",
    "        for file in files:\n",
    "            if file.endswith('.tif'):\n",
    "                file_path = os.path.join(root, file)\n",
    "\n",
    "                # Check file size\n",
    "                if os.path.getsize(file_path) < min_size_bytes:\n",
    "                    continue  # Skip this file if it's too small\n",
    "\n",
    "                path_parts = os.path.normpath(root).split(os.sep)\n",
    "                if len(path_parts) >= 3:\n",
    "                    dataset = path_parts[-2]\n",
    "                    session = path_parts[-1]\n",
    "                    dataset_list.append(dataset)\n",
    "                    session_list.append(session)\n",
    "                    file_list.append(file)\n",
    "\n",
    "    return dataset_list, session_list, file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Located 53 tiff stacks\n"
     ]
    }
   ],
   "source": [
    "# Get all tiff stacks and their paths\n",
    "data_dir = 'S:/pvd_data/'\n",
    "min_file_size = 1e8  # 100 MB\n",
    "datasets, sessions, files = scan_directories(data_dir, min_file_size)\n",
    "print(f\"Located {len(files)} tiff stacks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute pipeline\n",
    "for ii, file in enumerate(files):  # Slice like so to get a range of files[:1]\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # Set path\n",
    "    data_path = 'S:/pvd_data'\n",
    "    results_path = 'S:/pvd_analysis'\n",
    "    dataset = datasets[ii]\n",
    "    session = sessions[ii]\n",
    "    #tiff_stack_path = f\"{data_path}/{dataset}/{session}/{file}\"\n",
    "    output_path = f\"{results_path}/{dataset}/{session}/\"\n",
    "\n",
    "    # Process stack\n",
    "    print(f\"Processing tiff stack {ii}/{len(files)}\")\n",
    "    print(f\"{datasets[ii]} {sessions[ii]}\")\n",
    "    pvd = PVD(data_path, dataset, session, file)\n",
    "    pvd.run_pipeline()\n",
    "\n",
    "    # Save relevant numpy arrays\n",
    "    print(f\"Saving data to drive...\")\n",
    "    pvd.save_results(output_path, save_tiff=False, save_numpy=False, save_plotly=True, save_labeled_tiff=True)\n",
    "\n",
    "    del pvd\n",
    "\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline.\n",
      "Data loaded. Shape: (4, 188, 2044, 2042). Time: 49.10 seconds\n",
      "Data cropped. New shape: (4, 188, 2000, 2000). Time: 6.05 seconds\n",
      "Preprocessing complete. Time: 221.17 seconds\n",
      "Completed skeletonizing timepoint 1\n",
      "Completed skeletonizing timepoint 0\n",
      "Completed skeletonizing timepoint 2\n",
      "Completed skeletonizing timepoint 3\n",
      "Data skeletonized. Time: 308.47 seconds\n",
      "Number of tips per timepoint: [117, 112, 117, 122]\n",
      "Number of knots per timepoint: [342, 345, 335, 340]\n",
      "Outer segments found. Number of outer segments per timepoint: [34, 32, 32, 35]. Time: 6.23 seconds\n",
      "Matched 19 segments across all timepoints.\n",
      "Segments matched. Number of matched segments per timepoint: [19, 19, 19, 19]. Time: 0.04 seconds\n",
      "Grouped unmatched segments across each timepoint.\n",
      "Unmatched voxels identified. Unmatched segment shapes: [(188, 2000, 2000), (188, 2000, 2000), (188, 2000, 2000), (188, 2000, 2000)]. Time: 8.82 seconds\n",
      "Timepoint 1 volume labeled successfully.\n",
      "Timepoint 0 volume labeled successfully.\n",
      "Timepoint 3 volume labeled successfully.\n",
      "Timepoint 2 volume labeled successfully.\n",
      "All timepoints labeled successfully\n",
      "Total number of unique labels: 20\n",
      "Finished label_segmented_volume method\n",
      "Volumes labeled. Time: 49.57 seconds\n",
      "Generating volume changes DataFrame\n",
      "Volume changes DataFrame generated\n",
      "Volume changes DataFrame generated. Time: 52.75 seconds\n",
      "Pipeline complete. Total time: 702.22 seconds\n",
      "Saving data to drive...\n",
      "Skeleton visualizations saved to S:/pvd_analysis/DataSet01/exp240202_01_E_//visualizations\n",
      "Outer segment visualizations saved to S:/pvd_analysis/DataSet01/exp240202_01_E_//visualizations\n",
      "Labeled data saved as color TIFF files in S:/pvd_analysis/DataSet01/exp240202_01_E_/\n",
      "Volume changes DataFrame saved to S:/pvd_analysis/DataSet01/exp240202_01_E_//segment_change.csv\n"
     ]
    }
   ],
   "source": [
    "# # Set path to original test file\n",
    "# data_path = 'S:/pvd_data/'\n",
    "# results_path = 'S:/pvd_analysis'\n",
    "# dataset = 'DataSet01'\n",
    "# session = 'exp240202_01_E_'\n",
    "# file = 'exp240202_01_E.tif'\n",
    "# tiff_stack_path = f\"{data_path}/{dataset}/{session}_/{file}\"\n",
    "# output_path = f\"{results_path}/{dataset}/{session}/\"\n",
    "\n",
    "# # Process stack\n",
    "# pvd = PVD(data_path, dataset, session, file)\n",
    "# pvd.run_pipeline()\n",
    "\n",
    "# # Save relevant numpy arrays\n",
    "# print(f\"Saving data to drive...\")\n",
    "# pvd.save_results(output_path, save_tiff=False, save_numpy=False, save_plotly=True, save_labeled_tiff=True)\n",
    "\n",
    "# time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
